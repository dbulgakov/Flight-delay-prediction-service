{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.files.file_helper import load_binary_file, save_binary_file\n",
    "import utils.configuration\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.configuration.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_DATA_LOCATION = config.config['DEFAULT']['MERGED_DATA_LOCATION']\n",
    "MERGED_DATA_FILE_BIN = config.config['DEFAULT']['MERGED_DATA_FILE_BIN']\n",
    "PREPROCESSED_DATA_FILE_BIN = config.config['DEFAULT']['PREPROCESSED_DATA_FILE_BIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependent_variable_value(cancelled, delay_duration):\n",
    "    if cancelled == 1:\n",
    "        return 'cancelled_flight'\n",
    "    if delay_duration > 60:\n",
    "        return 'long_delay'\n",
    "    if delay_duration > 15:\n",
    "        return 'delay'\n",
    "    return 'no_delay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather(data_df, prefix):\n",
    "    data_df.loc[:, data_df.columns.str.startswith(prefix)] = data_df \\\n",
    "                                                .loc[:, data_df.columns.str.startswith(prefix)].fillna(value=0)\n",
    "    \n",
    "    data_df[prefix + 'fog'] = list(map(int , (data_df[prefix + 'wt01'] + data_df[prefix + 'wt02']).values > 0))\n",
    "    data_df[prefix + 'hail'] = list(map(int , (data_df[prefix + 'wt04'] + data_df[prefix + 'wt05']).values > 0))\n",
    "    data_df[prefix + 'damaging_wind'] = list(map(int , (data_df[prefix + 'wt10'] + data_df[prefix + 'wt11']).values > 0))\n",
    "    data_df[prefix + 'snow'] = list(map(int , (data_df[prefix + 'snow'] + data_df[prefix + 'wt09']).values > 0))\n",
    "    \n",
    "    data_df = data_df.rename(columns={'snwd': 'snow_depth', 'awnd': 'average_wind_speed', 'wt03': 'thunder', 'wt07': 'dust', 'wt08': 'haze'})\n",
    "\n",
    "    data_df[data_df.columns.drop(list(data_df.filter(regex=prefix + 'wt')))]\n",
    "    \n",
    "    return data_df.loc[:, ~data_df.columns.str.startswith(prefix + '_wt')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_variables(file_data):\n",
    "    \n",
    "    data_df = file_data.copy()\n",
    "    \n",
    "    data_df.columns = map(str.lower, data_df.columns)\n",
    "    \n",
    "    logging.debug('Processing origin weather')\n",
    "    \n",
    "    data_df = process_weather(data_df, 'origin_')\n",
    "    \n",
    "    logging.debug('Processing dest weather')\n",
    "\n",
    "    data_df = process_weather(data_df, 'dest_')\n",
    "    \n",
    "    logging.debug('Creating dependent variable')\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(16) as pool:\n",
    "        data_df['status'] = list(pool.map(get_dependent_variable_value, data_df['cancelled'], data_df['arr_delay'], chunksize=1_000))\n",
    "    \n",
    "    logging.debug('Peforming final data preparation')\n",
    "    \n",
    "    data_df = data_df.drop(['dep_delay', 'arr_delay', 'cancelled', 'crs_elapsed_time', \n",
    "                           'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay',\n",
    "                           'late_aircraft_delay'], axis=1)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(merged_data_location, merged_data_file_name, preprocessed_file_name):\n",
    "    logging.info('Loading historical data')\n",
    "\n",
    "    parsed_data = load_binary_file(merged_data_location, merged_data_file_name)\n",
    "    \n",
    "    logging.info('Starting to process data file')\n",
    "    \n",
    "    processed_data = process_data_variables(parsed_data)\n",
    "    \n",
    "    logging.info('Saving preprocessed data file')\n",
    "    \n",
    "    save_binary_file(processed_data, preprocessed_file_name, merged_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading historical data\n",
      "INFO:root:Starting to process data file\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(MERGED_DATA_LOCATION, MERGED_DATA_FILE_BIN, PREPROCESSED_DATA_FILE_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
