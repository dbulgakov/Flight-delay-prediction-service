{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "RND_STATE = 100412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(file_name)\n",
    "    with open(file_name, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "    return pickle.loads(bytes_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(file_name, data_to_save):\n",
    "    n_bytes = 2**31\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(data_to_save)\n",
    "    with open(file_name, 'w+b') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_FOLDER = '../data/dictionaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PICKLE = '../data/merged_data.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_CLF = '../data/best_clf.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file(DATA_PICKLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['origin'] == 'ALB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bulhakovdmytro/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "data2['average_wind_speed'].fillna((data2['average_wind_speed'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_preprocessing(data_df):\n",
    "    data_info = data_df.copy()\n",
    "    data_info = data_info.drop(['cancellation_code', 'cancelled', 'carrier_delay', 'dep_delay_new', 'late_aircraft_delay', 'nas_delay', 'security_delay', 'weather_delay', 'diverted', 'origin_city_name', 'dest_city_name'], axis = 1)\n",
    "    \n",
    "    data_info = data_info.drop(['snowfall', 'snow_depth', 'thunder', 'dust', 'haze', 'snow', 'fog', 'hail', 'damaging_wind'], axis = 1)\n",
    "    \n",
    "    data_info['crs_dep_time'] = list(map(int, working_df['crs_dep_time'].values / 100))    \n",
    "    return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = additional_preprocessing(working_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_group = data[['status', 'carrier']]\n",
    "airlines_group_num = airlines_group.groupby(['carrier']).size()\n",
    "airlines_group = data[['status', 'carrier']]\n",
    "airlines_group = airlines_group[(airlines_group['status'] != 'no_delay')]\n",
    "airlines_group_delays_num = airlines_group.groupby(['carrier']).size()\n",
    "delay_info = pd.DataFrame({'Carrier': np.unique(airlines_group.carrier.values), 'Number of flights': airlines_group_num.values, 'Number of delays': airlines_group_delays_num.values})\n",
    "delay_info['Delay index'] = delay_info['Number of delays'] / delay_info['Number of flights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_airline_delay_index(carrier):\n",
    "    return delay_info[delay_info['Carrier'] == carrier]['Delay index'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_df):\n",
    "    data_info = data_df.copy()\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(16) as pool:\n",
    "        data_info['airline_delay_index'] = list(pool.map(add_airline_delay_index, data_info['carrier'], chunksize=1_000))\n",
    "    \n",
    "    data_info = pd.get_dummies(data_info, columns=['dest'])\n",
    "    data_info['day_of_year'] = (data_info['fl_date'] - data_info['fl_date'].min())  / np.timedelta64(1,'D')\n",
    "    \n",
    "        \n",
    "    # data_info['crs_dep_time_time_sin'] = np.sin(2*np.pi*data_info.crs_dep_time/24.)\n",
    "    # data_info['crs_dep_time_time_cos'] = np.cos(2*np.pi*data_info.crs_dep_time/24.)\n",
    "    \n",
    "    data_info['weekend'] = np.where(data_info['day_of_week'] >= 6, 1, 0)\n",
    "    \n",
    "    data_info = data_info.drop(['fl_date', 'fl_num', 'origin', 'tail_num', 'carrier'], axis=1)\n",
    "    return data_info, data_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df, tmp = process_data(working_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(working_df.loc[:, working_df.columns != 'status'], working_df['status'], test_size = 0.2, random_state = RND_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester():\n",
    "    def __init__(self, parameters, model, scoring='f1_macro', njobs=-1, cv=3):\n",
    "        self.cv = GridSearchCV(model, param_grid=parameters, scoring = scoring, n_jobs = njobs, cv = cv, verbose = 1)\n",
    "    \n",
    "    def test_model(self, Xtrain, ytrain, Xtest, ytest):\n",
    "        self.cv.fit(Xtrain, ytrain);\n",
    "        print('Best score cv: ', self.cv.best_score_)\n",
    "        print('Params: ', self.cv.best_params_)\n",
    "    \n",
    "        y_predicted = self.cv.predict(Xtest)\n",
    "        print('F1 (micro) score on test sample:', f1_score(ytest, y_predicted, average='micro'))\n",
    "        print('F1 (weighted) score on test sample:', f1_score(ytest, y_predicted, average='weighted'))\n",
    "        \n",
    "    def best_estimator(self):\n",
    "        return self.cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1728 candidates, totalling 5184 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5184 out of 5184 | elapsed: 30.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.4866038733729732\n",
      "Params:  {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 16, 'max_features': 7, 'n_estimators': 60}\n",
      "F1 (micro) score on test sample: 0.8760162601626016\n",
      "F1 (weighted) score on test sample: 0.8663217975054347\n"
     ]
    }
   ],
   "source": [
    "param = {'criterion':['gini', 'entropy'], 'max_features':[1, 2, 3, 4, 5, 6, 7, 'log2', 'auto'],\n",
    "         'max_depth':[2, 4, 8, 16, 32, 64], 'class_weight':['balanced', None], 'n_estimators': [30, 40, 50, 60], 'bootstrap': [True, False]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = RandomForestClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "rf_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Random Forest Classifier', 'clf': rf_clf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (micro) score on test sample: 0.5362536052155895\n",
      "F1 (macro) score on test sample: [0.46153846 0.21259843 0.93462393]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = rf_clf.predict(X_test)\n",
    "print('F1 (macro) score on test sample:', f1_score(y_test, y_predicted, average='macro'))\n",
    "print('F1 (macro) score on test sample:', f1_score(y_test, y_predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C': np.linspace(0.01, 0.03, num=2), \n",
    "              'class_weight':['balanced', None], 'kernel':['linear'],\n",
    "              'decision_function_shape' : ['ovo', 'ovr', None]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = SVC(random_state=RND_STATE, cache_size=2048))\n",
    "# mt.test_model(X_train, y_train, X_test, y_test)\n",
    "# svc_clf = mt.best_estimator()\n",
    "# classifiers.append({'name': 'SVC', 'clf': svc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   23.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.3467505236915829\n",
      "Params:  {'algorithm': 'SAMME.R', 'learning_rate': 1.0}\n",
      "F1 (micro) score on test sample: 0.9009872241579558\n",
      "F1 (weighted) score on test sample: 0.85489123183182\n"
     ]
    }
   ],
   "source": [
    "param = {'algorithm': ['SAMME.R', 'SAMME'], 'learning_rate': [0.1, 0.3, 0.6, 0.8, 1.0]}\n",
    "mt = ModelTester(parameters = param, model = AdaBoostClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "adc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'AdaBoost Classifier', 'clf': adc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 out of 168 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.44622380964057645\n",
      "Params:  {'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 5, 'presort': False, 'random_state': 100412, 'splitter': 'best'}\n",
      "F1 (micro) score on test sample: 0.8426248548199767\n",
      "F1 (weighted) score on test sample: 0.8437562066173171\n"
     ]
    }
   ],
   "source": [
    "param = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], \n",
    "         'class_weight' : ['balanced'], 'random_state':[RND_STATE], 'presort':[True, False]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = DecisionTreeClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "dtc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Decision Tree Classifier', 'clf': dtc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed: 25.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.3468096104253847\n",
      "Params:  {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 30, 'p': 1, 'weights': 'distance'}\n",
      "F1 (micro) score on test sample: 0.9027293844367015\n",
      "F1 (weighted) score on test sample: 0.8595549073713904\n"
     ]
    }
   ],
   "source": [
    "param = {'n_neighbors': [30, 50, 65, 70], 'weights': ['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "         'leaf_size' : [10, 15, 20], 'p':[1, 2]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = KNeighborsClassifier())\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "knn_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'K-Neighbors Classifier', 'clf': knn_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score cv:  0.44898212892711603\n",
      "Params:  {'loss': 'deviance', 'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 300, 'presort': True}\n",
      "F1 (micro) score on test sample: 0.9044715447154471\n",
      "F1 (weighted) score on test sample: 0.867061334328921\n"
     ]
    }
   ],
   "source": [
    "param = {'loss': ['deviance'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], 'presort':[True, False],\n",
    "         'n_estimators':[200, 300], 'min_samples_leaf' : [3]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = GradientBoostingClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "gbc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Gradient Boosting Classifier', 'clf': gbc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results per classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_importances_internal(data_df, imp_list):\n",
    "    print('Top 10 features:')\n",
    "    val_zip = zip(data_df.columns, imp_list) \n",
    "    for a, b, in sorted(val_zip, key = lambda zp_gb: zp_gb[1], reverse = True)[:10]:\n",
    "        print(\"{0}: {1}\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_importances(data_df, model):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print_importances_internal(data_df, model.feature_importances_)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print_importances_internal(data_df, model.coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d2949613574da6b5af38bca81d8aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=5)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier\n",
      "F1 score:  0.8857107228197686\n",
      "Top 10 features:\n",
      "day_of_year: 0.1906763850269155\n",
      "average_wind_speed: 0.16357845145130895\n",
      "day_of_month: 0.1450401775580273\n",
      "crs_elapsed_time: 0.10335953052856928\n",
      "crs_dep_time: 0.09999126640853984\n",
      "day_of_week: 0.06748131863980306\n",
      "month: 0.0662450973889621\n",
      "airline_delay_index: 0.040061246723587365\n",
      "quarter: 0.02713779858633902\n",
      "weekend: 0.012999320626495524\n",
      "\n",
      "AdaBoost Classifier\n",
      "F1 score:  0.9470832164840918\n",
      "Top 10 features:\n",
      "day_of_year: 0.36\n",
      "crs_elapsed_time: 0.12\n",
      "crs_dep_time: 0.1\n",
      "day_of_month: 0.1\n",
      "average_wind_speed: 0.08\n",
      "month: 0.08\n",
      "airline_delay_index: 0.04\n",
      "quarter: 0.02\n",
      "dest_CLT: 0.02\n",
      "dest_DTW: 0.02\n",
      "\n",
      "Decision Tree Classifier\n",
      "F1 score:  0.8414935030226363\n",
      "Top 10 features:\n",
      "day_of_year: 0.1623640684932886\n",
      "average_wind_speed: 0.15944477768928256\n",
      "day_of_month: 0.12274598903177944\n",
      "crs_elapsed_time: 0.11171249419092372\n",
      "crs_dep_time: 0.10660056628939428\n",
      "day_of_week: 0.08027070950606444\n",
      "month: 0.066253338149032\n",
      "airline_delay_index: 0.03919742600882441\n",
      "quarter: 0.03605067823701363\n",
      "weekend: 0.02159372545942422\n",
      "\n",
      "K-Neighbors Classifier\n",
      "F1 score:  0.9459038615020126\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "F1 score:  0.9418817551019735\n",
      "Top 10 features:\n",
      "day_of_year: 0.27932825290658797\n",
      "average_wind_speed: 0.16313032703232058\n",
      "crs_elapsed_time: 0.135415574104321\n",
      "crs_dep_time: 0.10347341223388402\n",
      "day_of_month: 0.10296924690261106\n",
      "month: 0.044741366846506085\n",
      "airline_delay_index: 0.03927415917370957\n",
      "day_of_week: 0.03267084404401242\n",
      "dest_ORD: 0.01287510196344979\n",
      "dest_BWI: 0.012269863993930222\n"
     ]
    }
   ],
   "source": [
    "results_data = []\n",
    "for clf in log_progress(classifiers, every = 1):\n",
    "    print('\\n' + clf['name'])\n",
    "    score = f1_score(clf['clf'].predict(X_test), y_test, average='weighted')\n",
    "    print('F1 score: ', score)\n",
    "    results_data.append({'Classifier': clf['name'], 'F1 Score': score})\n",
    "    print_importances(working_df.loc[:, working_df.columns != 'status'], clf['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(BEST_CLF, rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
